{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_Ac-hElYtZu",
        "outputId": "ee4217f2-a56e-4d62-8231-baa04da39a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Address already in use\n",
            "Port 5004 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://4929-35-234-46-166.ngrok-free.app\" -> \"http://localhost:5004\"\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install flask pyngrok transformers torch nltk seaborn matplotlib scikit-learn\n",
        "\n",
        "# Import necessary libraries\n",
        "from flask import Flask, jsonify, request\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import nltk\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt')  # Ensure punkt is downloaded\n",
        "nltk.download('punkt_tab')  # Download the missing punkt_tab resource\n",
        "\n",
        "# Load BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define the claim similarity function\n",
        "def check_claim_similarity(evidence, claim, threshold=0.8):\n",
        "    inputs_evidence = tokenizer(evidence, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    inputs_claim = tokenizer(claim, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs_evidence = model(**inputs_evidence, output_hidden_states=True)\n",
        "        outputs_claim = model(**inputs_claim, output_hidden_states=True)\n",
        "\n",
        "    evidence_embedding = outputs_evidence.hidden_states[-1].mean(dim=1).cpu().numpy()\n",
        "    claim_embedding = outputs_claim.hidden_states[-1].mean(dim=1).cpu().numpy()\n",
        "\n",
        "    similarity_score = cosine_similarity(evidence_embedding, claim_embedding)[0][0]\n",
        "\n",
        "    is_claim_true = similarity_score >= threshold\n",
        "    result = \"Claim is likely true.\" if is_claim_true else \"Claim is likely false.\"\n",
        "\n",
        "    refuting_part = \"\"\n",
        "    if not is_claim_true:\n",
        "        sentences = nltk.sent_tokenize(evidence)\n",
        "        sentence_similarities = []\n",
        "        for sentence in sentences:\n",
        "            inputs_sentence = tokenizer(sentence, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "            with torch.no_grad():\n",
        "                outputs_sentence = model(**inputs_sentence, output_hidden_states=True)\n",
        "            sentence_embedding = outputs_sentence.hidden_states[-1].mean(dim=1).cpu().numpy()\n",
        "            sentence_similarity = cosine_similarity(sentence_embedding, claim_embedding)[0][0]\n",
        "            sentence_similarities.append((sentence, sentence_similarity))\n",
        "        refuting_sentence = min(sentence_similarities, key=lambda x: x[1])\n",
        "        refuting_part = refuting_sentence[0]\n",
        "\n",
        "    return {\n",
        "        \"claim\": result,\n",
        "        \"refuting_line\": refuting_part\n",
        "    }\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Define the /check_claim_similarity endpoint\n",
        "@app.route('/check_claim_similarity', methods=['POST'])\n",
        "def check_similarity():\n",
        "    data = request.json\n",
        "    evidence = data.get(\"evidence\", \"\")\n",
        "    claim = data.get(\"claim\", \"\")\n",
        "    threshold = data.get(\"threshold\", 0.85)\n",
        "\n",
        "    result = check_claim_similarity(evidence, claim, threshold)\n",
        "    return jsonify(result)\n",
        "\n",
        "# Function to run Flask app in a thread\n",
        "# Function to run Flask app in a thread\n",
        "def run_app():\n",
        "    app.run(port=5004)  # Change port to 5004 or another available port\n",
        "\n",
        "\n",
        "# Start Flask in a separate thread\n",
        "thread = threading.Thread(target=run_app)\n",
        "thread.start()\n",
        "\n",
        "# Set up ngrok tunnel to expose the app\n",
        "ngrok.set_auth_token(\"2okt49NJk73E4y0PWyIA0xdVRJ6_2n6Lvuuhnu9Dp4VqXcK48\")  # Replace with your actual ngrok auth token\n",
        "# Set up ngrok tunnel to expose the app on the correct port\n",
        "public_url = ngrok.connect(5004)  # Change to match Flask's running port (5004)\n",
        "print(f\"Public URL: {public_url}\")\n",
        "\n",
        "# Ensure Content-Type: application/json when making POST requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://127.0.0.1:5004/check_claim_similarity\"  # or use the ngrok public URL\n",
        "headers = {\"Content-Type\": \"application/json\"}\n",
        "data = {\n",
        "    \"evidence\": \"The scientific community widely agrees that smoking cigarettes has severe negative effects on health, including increasing the risk of lung cancer, heart disease, stroke, and respiratory illnesses. Decades of research have shown that smoking damages almost every organ in the body and significantly reduces life expectancy\",\n",
        "    \"claim\": \"Smoking cigarettes has no harmful effects on human health.\",\n",
        "    \"threshold\": 0.85\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=data, headers=headers)\n",
        "print(response.json())\n"
      ],
      "metadata": {
        "id": "SNfBOEiuYu61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "758656ce-63d4-44cc-c5af-6851c378d13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [13/Nov/2024 08:59:24] \"POST /check_claim_similarity HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'claim': 'Claim is likely false.', 'refuting_line': 'Decades of research have shown that smoking damages almost every organ in the body and significantly reduces life expectancy'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BnAdEG8cJUVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}